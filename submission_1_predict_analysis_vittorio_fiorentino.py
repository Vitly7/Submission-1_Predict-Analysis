# -*- coding: utf-8 -*-
"""Submission_1_Predict_Analysis_Vittorio_Fiorentino.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wXdHnf_XauN2G8jitDAIUm5jeWNL_onb

# Data Understanding

- **Nama:** [Vittorio Fiorentino]
- **Email:** [a541ybm493@devacademy.id]
- **ID Dicoding:** [A541YBM493]

## Objective:
- Prediksi Harga menggunakan Machine Learning

## Sumber Dataset:
https://www.kaggle.com/datasets/shivachandel/kc-house-data

## Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
import os, shutil
import zipfile

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor

"""## Load Dataset"""

# Import module yang disediakan google colab untuk kebutuhan upload file

from google.colab import files
files.upload()

# Hapus jika .kaggle bukan folder
#if os.path.exists("/root/.kaggle") and not os.path.isdir("/root/.kaggle"):
#    os.remove("/root/.kaggle")

# Buat folder .kaggle dan pindahkan file
os.makedirs("/root/.kaggle", exist_ok=True)
shutil.move("kaggle.json", "/root/.kaggle/kaggle.json")

# Atur permission agar bisa diakses
os.chmod("/root/.kaggle/kaggle.json", 600)

!kaggle datasets download -d shivachandel/kc-house-data
!unzip kc-house-data.zip

house = pd.read_csv('kc_house_data.csv')

house

"""**Dataset House**

Dataset ini diambil dari kaggle yaitu kc_house_data.csv. Dataset berisi informasi mengenai spesifikasi properti beserta harga.

## EDA
"""

house.info()

"""**Struktur Data**

- Terdapat missing Value pada sqft_above dengan jumlah 21611 dari 21613
- Semua kolom bertipe Numeric (Kolom Date harusnya bertipe datetime)

**Insight**

- Kita akan berfokus pada beberapa kolom variabel saja, sehingga variable yang tidak perlu akan di drop.


Penjelasan 21 Fitur Awal:
1. id
- ID unik untuk setiap properti. Digunakan sebagai identifikasi individual dalam dataset.

2. date
- Tanggal penjualan rumah. Format umum: YYYYMMDDT000000.

3. price
- Harga jual rumah (dalam USD). Ini adalah variabel target jika ingin melakukan prediksi harga.

4. bedrooms
- Jumlah kamar tidur di rumah.

5. bathrooms
- Jumlah kamar mandi (dinyatakan dalam angka desimal; misal 1.5 berarti 1 kamar mandi penuh dan 1 kamar mandi kecil).

6. sqft_living
- Luas area yang dapat dihuni (livable) dalam satuan kaki persegi.

7. sqft_lot
- Luas total tanah properti (termasuk bangunan dan halaman), dalam kaki persegi.

8. floors
- Jumlah lantai bangunan rumah.

9. waterfront
- Indikator apakah rumah memiliki pemandangan langsung ke air (danau, laut, dll).
-  Nilai: 0 (tidak), 1 (ya).

10. view
- Indeks visualisasi rumah terhadap pemandangan luar. Skala 0–4; semakin tinggi, semakin bagus pandangan rumah.

11. condition
- Kondisi umum rumah (bukan renovasi). Skala 1–5; 1 paling buruk, 5 sangat baik.

12. grade
- Penilaian kualitas konstruksi dan desain rumah oleh King County (bukan kondisi). Skala 1–13.

13. sqft_above
- Luas area bangunan di atas tanah (tidak termasuk basement), dalam kaki persegi.

14. sqft_basement
- Luas area basement (bawah tanah), dalam kaki persegi.

15. yr_built
- Tahun rumah pertama kali dibangun.

16. yr_renovated
- Tahun terakhir rumah direnovasi. Jika tidak pernah direnovasi, bernilai 0.

17. zipcode
- Kode pos wilayah rumah berada.

18. lat
- Latitude (garis lintang) lokasi properti.

19. long
- Longitude (garis bujur) lokasi properti.

20. sqft_living15
- Rata-rata luas area livable dari 15 rumah tetangga terdekat.

21. sqft_lot15
- Rata-rata luas tanah dari 15 rumah tetangga terdekat.

### Handling Missing Value

Pada code dibawah menunjukkan ada missing value pada kolom sqft_above
"""

house.isna().sum()

"""### Handling Outliers"""

numerical_cols = ['price','bedrooms','bathrooms','sqft_living','floors']

plt.figure(figsize=(14, 14))  # lebih lebar
for i, col in enumerate(numerical_cols):
    plt.subplot(3, 2, i + 1)
    sns.boxplot(y=house[col])
    plt.title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()

"""Penjelasan BoxPlot:

1. bathrooms
Boxplot: Terlihat banyak outlier di atas (hingga 8 kamar mandi). Rumah dengan lebih dari 4–5 kamar mandi itu jarang dan bisa dikategorikan outlier.

2. sqft_living
Boxplot: Outlier ekstrem sangat banyak di sisi atas (hingga >13.000 sqft). Rumah dengan luas >8000 sqft adalah mansion dan sangat tidak umum, bisa mendistorsi model.

3. floors
Boxplot: Hampir tidak ada outlier. Rentang antara 1 hingga 3.5 lantai, distribusinya cukup stabil.

4.  bedrooms
Boxplot: Outlier bisa terjadi untuk rumah dengan 33 kamar tidur.

5. price
Boxplot: Harga memang ada outliers. Mungkin karena ada rumah mahal/mansion

# Data Preparation

### Drop Missing Value pada sqft_above
"""

house = house.dropna(subset=['sqft_above'])

"""### Perkecil Scope Variable Dataset

- Hal ini bertujuan untuk menyederhanakan model dan menghindari overfitting.
- Beberapa variabel yang dirasa tidak terlalu berpengaruh dengan signifikan akan di drop. Sehingga kita hanya mengambil variabel ( price, bedrooms, bathrooms, sqft_living, floors, waterfront, condition, grade, yr_built, yr_renovated)
"""

house = house.drop(['id', 'date', 'zipcode', 'view', 'lat', 'long', 'sqft_basement', 'sqft_lot', 'sqft_lot15', 'sqft_above', 'sqft_living15'], axis=1)

house.head()

house.describe()

"""**Insight:**

- Kolom bedrooms dan bathrooms memiliki data bernilai 0. Sedikit ambigu jika rumah tidak punya bedrooms dan bathrooms. Tapi bisa saja memang ada. Kita berspekulasi bahwa nilai 0 itu tidak mungkin, sehingga akan kita buang.

### Handling Nilai 0 Pada Bedroom dan Bathrooms
"""

bedrooms = (house.bedrooms == 0).sum()
print(bedrooms)

"""Bedrooms yang bernilai 0 memiliki 13 baris."""

house.loc[(house['bedrooms']==0)]

"""Dari hasil ini bisa dilihat memang anomali karena grade rumah termasuk mayoritas tinggi. Sehingga data ini akan dibuang/drop"""

bathrooms = (house.bathrooms == 0).sum()
print(bathrooms)

"""Bathrooms yang bernilai 0 memiliki 3 baris"""

house.loc[(house['bathrooms']==0)]

"""Dari hasil ini bisa dilihat meskipun bathrooms, tetapi masih ada bedrooms. Jika dilihat dari yr_built kisaran 1948-1966 yang dimana termasuk sudah tua dengan grade yang normal.

- Dapat disimpulkan data ini termasuk normal, sehingga tetap akan digunakan

### Drop nilai 0 pada Bedrooms
"""

# Drop baris dengan nilai 'Bedrooms' = 0
house = house.loc[(house[['bedrooms']]!=0).all(axis=1)]

# Cek ukuran data untuk memastikan baris sudah di-drop
house.shape

"""#### Handling Outliers dengan Winsorize

Winsorize adalah teknik statistik yang digunakan untuk mengurangi pengaruh outlier ekstrem dalam data dengan cara mengubah (bukan menghapus) nilai-nilai ekstrem tersebut menjadi nilai yang lebih dekat ke nilai tengah (biasanya batas persentil tertentu).
"""

def winsorize_iqr_df(house, columns):
    house_winsorized = house.copy()  # salin dataframe supaya data asli aman

    for col in columns:
        Q1 = house[col].quantile(0.25)
        Q3 = house[col].quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        house_winsorized[col] = np.where(
            house_winsorized[col] < lower_bound, lower_bound,
            np.where(house_winsorized[col] > upper_bound, upper_bound, house_winsorized[col])
        )

    return house_winsorized

# Misalnya kolom yang mau di-winsorize:
num_cols = ['bathrooms', 'sqft_living', 'bedrooms']

# Terapkan winsorization ke dataframe house
house_winsorized = winsorize_iqr_df(house, num_cols)

plt.figure(figsize=(15, 10))  # ukuran lebih besar agar tidak sempit

# Boxplot bathrooms
plt.subplot(2, 3, 1)
sns.boxplot(y=house_winsorized['bathrooms'])
plt.title('Boxplot Bathrooms')

# Boxplot sqft_living
plt.subplot(2, 3, 2)
sns.boxplot(y=house_winsorized['sqft_living'])
plt.title('Boxplot Sqft Living')

# Boxplot bedrooms
plt.subplot(2, 3, 3)
sns.boxplot(y=house_winsorized['bedrooms'])
plt.title('Boxplot Bedrooms')

# Boxplot floors
plt.subplot(2, 3, 4)
sns.boxplot(y=house_winsorized['floors'])
plt.title('Boxplot Floors')

# Boxplot price
plt.subplot(2, 3, 5)
sns.boxplot(y=house_winsorized['price'])
plt.title('Boxplot Price')

plt.tight_layout()
plt.show()

"""**Penjelasan**:

Setelah berhasil menangani outlier dengan winsorize, data sudah stabil. Variabel price merupakan nilai target jadi tetap dibiarkan meskipun ada outlier karena akan mempengaruhi akurasi model. Model justru perlu belajar bahwa properti tertentu memang bisa mahal.
"""

house_winsorized.info()

house_winsorized.describe()

# Membuat kategori bins untuk sqft_living

# Agregasi rata-rata harga berdasarkan kategori luas rumah
df_agg = house_winsorized.groupby('sqft_living').agg({'price': 'mean'}).reset_index()

plt.figure(figsize=(12,6))
plt.title("Rata-rata Harga Rumah Berdasarkan Rentang Luas Rumah")
sns.barplot(x='sqft_living', y='price', data=df_agg)
plt.xlabel("Rentang Luas Rumah (sqft)")
plt.ylabel("Rata-rata Harga Rumah (Price)")
plt.show()

"""Berdasarkan hasil visualisasi, berikut adalah beberapa insight yang bisa didapatkan:

- Distribusi Harga Jual Berdasarkan Luas Rumah: Bar chart menunjukkan harga jual ('selling_price') untuk berbagai kategori luas rumah ('sqft_living'). Sumbu X adalah luas rumah dan sumbu Y adalah harga jual.

- Kategori dengan Harga Jual Terendah: Range 0-1000

- Kategori dengan Harga Jual Tertinggi: Range 4001+

- Tren Peningkatan Harga Jual: Terlihat jelas ada tren peningkatan harga jual dari kiri ke kanan.

### Univariate Analysis

- Analisis Satu Variabel
- Tidak mempelajari hubungan dengan variabel lain
"""

numerical_features = ['price', 'bathrooms', 'bedrooms', 'floors', 'sqft_living', 'yr_built', 'yr_renovated']
categorical_features = ['waterfront', 'condition', 'grade']

"""#### Categorical Features"""

for feature in categorical_features:
    count = house_winsorized[feature].value_counts()
    percent = 100 * house_winsorized[feature].value_counts(normalize=True)
    df = pd.DataFrame({'jumlah sampel': count, 'persentase': percent.round(1)})

    print(f"\nDistribusi untuk fitur: {feature}")
    print(df)

    count.plot(kind='bar', title=f'Distribusi {feature}')
    plt.xlabel(feature)
    plt.ylabel('Jumlah')
    plt.show()

"""#### Numerical Features"""

house_winsorized.hist(bins=50, figsize=(20,15))
plt.show()

"""### Multivariate Analysis

- Analisis Banyak Variabel
- Digunakan untuk menemukan hubungan, korelasi, atau pengaruh antar variabel.

#### Categorical Features
"""

categorical_features = ['waterfront', 'condition', 'grade']

for col in categorical_features:
    sns.catplot(x=col, y="price", kind="bar", dodge=False, height=4, aspect=2.5,
                data=house_winsorized, palette="Set2")
    plt.title(f"Rata-rata 'price' berdasarkan kategori {col}")
    plt.xlabel(col)
    plt.ylabel("Rata-rata Price")

"""**Penjelasan**:

- Grafik menunjukkan bahwa rumah yang memiliki waterfront (dekat/punya akses ke air, ditandai dengan 1) memiliki rata-rata harga jauh lebih tinggi dibandingkan rumah yang tidak memiliki waterfront (ditandai dengan 0). Artinya, faktor lokasi terhadap air berpengaruh signifikan terhadap harga properti.

- Semakin tinggi nilai condition, rata-rata harga ikut naik:

  - Condition 1–2: sekitar 330 ribu.

  - Condition 3–4: melonjak ke kisaran 520–540 ribu.

  - Condition 5: tertinggi, ±610 ribu.

    Jadi, kondisi yang lebih baik berasosiasi dengan harga rata-rata yang lebih tinggi, dengan lonjakan paling besar terjadi setelah kategori 2.

- Grafik menunjukkan bahwa semakin tinggi grade, rata-rata harga (price) meningkat tajam:

  - Grade 3–8: harga relatif stabil di bawah 700 ribu.

  - Grade 9–11: mulai naik signifikan, tembus lebih dari 1 juta.

  - Grade 12–13: lonjakan tajam, hingga lebih dari 3 juta di grade 13.

    Kesimpulan: grade berpengaruh kuat terhadap harga, terutama di grade tinggi.

#### Numerical Features
"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(house_winsorized, diag_kind = 'kde')

numerical_features = ['price', 'bathrooms', 'bedrooms', 'floors', 'sqft_living', 'yr_built', 'yr_renovated']

plt.figure(figsize=(10, 8))
correlation_matrix = house_winsorized[numerical_features].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""**Penjelasan Matrix Correlation**:

1.  Korelasi terhadap price:
- Tinggi:

  - sqft_living (0.65): Semakin besar luas rumah, semakin tinggi harganya.

  - bathrooms (0.48): Lebih banyak kamar mandi cenderung menaikkan harga.

- Sedang:

  - bedrooms (0.32), floors (0.26)

- Rendah:

  - yr_renovated (0.13)

  - yr_built (0.05): Tahun dibangun hampir tidak berpengaruh langsung terhadap harga.

2. Korelasi antarfungsi lain:
- bathrooms dan sqft_living punya korelasi tinggi (0.75), menunjukkan bahwa rumah lebih besar cenderung memiliki lebih banyak kamar mandi.

- yr_built dan yr_renovated berkorelasi negatif (-0.22), artinya rumah yang lebih lama dibangun cenderung lebih sering direnovasi.

Kesimpulan:

Fitur paling relevan terhadap price adalah sqft_living, lalu bathrooms. Fitur seperti yr_built atau yr_renovated punya pengaruh sangat kecil terhadap harga berdasarkan korelasi linier.

### Menyimpan dataset yang telah dibersihkan ke variabel utama
"""

house = house_winsorized.copy()
house.head()

"""## Train Test Split"""

X = house.drop(["price"],axis =1)
y = house["price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

"""Split Data:

Training 90 : Test 10


"""

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## Standarisasi Numeric"""

scaler = StandardScaler()

numerical_features = ['bedrooms', 'bathrooms', 'sqft_living', 'floors', 'yr_built','yr_renovated']
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""# Model Deployment"""

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""Analisis Model akan menggunakan tiga jenis model, yaitu:

KNN, RandomForest, Boosting

## KNN

Lazy Learning: Tidak melakukan proses pelatihan dalam arti tradisional. Hanya menyimpan data training.

Prediksi:

1. Untuk setiap titik data baru (X_test), hitung jarak (biasanya Euclidean) ke semua data training.

2. Pilih k tetangga terdekat (dalam contohmu, k=7).

3. Ambil rata-rata dari nilai target (y_train) dari 7 tetangga tersebut.
"""

knn = KNeighborsRegressor(n_neighbors=7)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""## Random Forest

Cara kerja:

1. Buat banyak pohon keputusan (di sini 50 pohon).

2. Setiap pohon:

  - Dibuat dari sampel acak dengan pengembalian dari data training (bootstrap sampling).

  - Saat membelah node, hanya subset acak dari fitur yang dipertimbangkan.

3. Setiap pohon membuat prediksi, lalu rata-ratanya diambil (untuk regresi).

Parameter penting:

- n_estimators=50: jumlah pohon dalam hutan.

- max_depth=16: membatasi kedalaman pohon → mencegah overfitting.

- n_jobs=-1: gunakan semua core CPU untuk training (paralel).
"""

# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""## Metode Adaptive Boosting

Cara kerja (regresi):

1. Model pertama (weak learner) dilatih pada data asli.

2. Residual (kesalahan prediksi) dihitung.

3. Model selanjutnya dilatih untuk memprediksi residual tersebut, bukan nilai aslinya.

4. Proses berulang: setiap model mencoba memperbaiki kesalahan model sebelumnya.

5. Prediksi akhir adalah gabungan (weighted sum) dari semua model.

Spesifik pada kode:

1. AdaBoostRegressor menggunakan DecisionTreeRegressor depth=1 sebagai default weak learner.

2. learning_rate=0.05: mengatur kontribusi tiap model terhadap prediksi akhir.

3. random_state=55: memastikan hasil yang reprodusibel.
"""

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""## Scaling Pada Data Uji

Fungsi scaling (normalisasi atau standarisasi) pada data uji (test set) adalah:

- Menjadikan skala data uji konsisten dengan data latih, agar model dapat membuat prediksi yang akurat.
"""

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""# Evaluasi Model"""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Panggil mse
mse

"""✅ Kesimpulan:

- Boosting memiliki generalisasi terbaik (perbedaan train-test kecil).

- Random Forest overfitting parah (akurat di train, tapi test buruk).

- KNN kurang cocok karena overfitting sedang (train cukup bagus, test lumayan bagus).
"""

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""📌 Interpretasi Singkat:

KNN: MSE di data test cukup tinggi, menunjukkan model sedikit overfitting.

RF: MSE Train rendah sedangkan MSE Test sangat tinggi, menunjukkan model sangat overfitting.

Boosting: MSE Train dan Test hampir sama, menunjukkan model yang paling stabil

✅ Kesimpulan:

KNN dan Boosting lebih cocok digunakan dibanding RF untuk data ini.

Boosting mungkin pilihan terbaik karena Model paling stabil.

## Uji Data
"""

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Evaluasi Akurasi Prediksi:

Hasil Asli = 270000
- KNN	307818.9 	 ->	Paling dekat
- RandomForest	320719.8	 ->	Cukup dekat
- Boosting	383666.0	 ->	Cukup jauh dari aslinya

**Kesimpulan:**

Meskipun Boosting memiliki performa rata-rata paling stabil (dari MSE test sebelumnya), dalam prediksi individual ini, Random Forest adalah model paling akurat, karena menghasilkan prediksi terdekat terhadap nilai asli. Maka, Random Forest bisa diprioritaskan sebagai model final, terutama jika fokusnya adalah akurasi individual.
"""

